{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wstęp do Uczenia Maszynowego \n",
    "##### Laboratorium 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "-----\n",
    "Wczytaj dane `pima.csv`.\n",
    "\n",
    "a) Podziel dane za część treningową i testową (3:2).\n",
    "\n",
    "b) Dopasuj model drzewa do danych treningowych.\n",
    "\n",
    "c) Dopasuj model regresji logistycznej do danych treningowych.\n",
    "\n",
    "d) Podaj miary: czułość, precyzja, AUC dla obu modeli na zbiorze testowym.\n",
    "\n",
    "e) Narysuj krzywą ROC dla obu modeli na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2\n",
    "-----\n",
    "Eksperyment symulacyjny. Wygenerujmy dane w następujący sposób. Niech $n = 200$, $p = 5$. Wektor $\\beta_0 = 1$, $\\beta_1 = [2, 1, 0.5, 0.01, 0]$, $x_i \\sim N_p(0, I)$ dla $i = 1,2, \\dots, n$. $y_i$ pochodzi z rozkładu $Bern(p_i)$, gdzie $p_i=\\frac{exp(\\beta_0 + x_{i\\cdot}\\beta_1)}{1 + exp(\\beta_0 + x_{i\\cdot}\\beta_1)}$.\n",
    "\n",
    "a) Dopasuj model regresji logistycznej. Porównaj prawdziwe wartości wektora $\\beta$ z wyestymowanymi.\n",
    "\n",
    "b) Dopasuj model regresji logistycznej z regularyzacją $L2$ i współczynnikami $C = (10, 5, 2, 1, 0.5, 0.1, 0.01, 0.005)$. jak zmienieją się współczynniki wraz ze wzrostem współczynnika lambda?\n",
    "\n",
    "c) Dopasuj model regresji logistycznej z regularyzacją $L1$ i współczynnikami $C = (10, 5, 2, 1, 0.5, 0.1, 0.01, 0.005)$. jak zmienieją się współczynniki wraz ze wzrostem współczynnika lambda?\n",
    "\n",
    "d) Powtórz eksperyment 500 razy dla modelu logistycznego bez regularyzacji, z regularyzacją $L2$ i parametrem $C=1$ i regularyzacją $L1$ i parametrem $C=1$. Oblicz MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3\n",
    "-----\n",
    "Wpływ skalowania zmiennych. Dopasuj modele regresji logistycznej\n",
    "1. z regularyzacją L2 dla danych bez skalowania i dla danych ze skalowaniem zmiennych (StandardScaler);\n",
    "2. z regularyzacją L1 dla danych bez skalowania i dla danych ze skalowaniem zmiennych (StandardScaler).\n",
    "\n",
    "Porównaj współczynniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Wczytanie danych\n",
    "credit = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
    "df = credit.frame\n",
    "\n",
    "print(df.shape)\n",
    "sel_cols = ['age', 'existing_credits', 'duration', 'credit_amount', 'savings_status', 'credit_history', 'class']\n",
    "df = df[sel_cols]\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = (df['class'] == 'good').astype(int)\n",
    "\n",
    "X = df.drop(columns='class')\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresja logistyczna z regularyzacją Elastic Net\n",
    "\n",
    "Regresja logistyczna estymuje parametry $\\boldsymbol{\\beta}$ poprzez minimalizację funkcji kosztu (ujemnej log-likelihood) z dodaną karą regularyzacyjną:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\boldsymbol{\\beta}) \n",
    "= -\\frac{1}{n} \\sum_{i=1}^{n} \n",
    "\\Big[ \n",
    "y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \n",
    "\\Big]\n",
    "+ \\lambda \\left(\n",
    "\\alpha \\|\\boldsymbol{\\beta}\\|_1 + \n",
    "\\frac{1 - \\alpha}{2} \\|\\boldsymbol{\\beta}\\|_2^2\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "gdzie:\n",
    "\n",
    "- $p_i = \\frac{1}{1 + e^{-(\\beta_0 + \\mathbf{x}_i^\\top \\boldsymbol{\\beta})}}$  — to prawdopodobieństwo przynależności do klasy pozytywnej,  \n",
    "- $\\lambda > 0$ — współczynnik regularyzacji (im większy, tym silniejsza kara),  \n",
    "- $\\alpha \\in [0, 1]$ — współczynnik mieszający między karą $L_1$ i $L_2$:\n",
    "  - dla $\\alpha = 1$ → **Lasso (L1)**,\n",
    "  - dla $\\alpha = 0$ → **Ridge (L2)**,\n",
    "  - dla $0 < \\alpha < 1$ → **Elastic Net** (mieszanka obu).\n",
    "\n",
    "---\n",
    "W implementacji `scikit-learn` parametr `C` jest odwrotnością $\\lambda$:\n",
    "\n",
    "$$\n",
    "C = \\frac{1}{\\lambda},\n",
    "$$\n",
    "a parametrowi $\\alpha$ odpowiada `l1_ratio`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4\n",
    "-----\n",
    "   Dopasuj modele regresji logistycznej z regularyzacją L1 (penalty='l1') dla wartości  \n",
    "     $$\n",
    "     C \\in \\{0.001, 0.01, 0.1, 0.5, 1, 2, 5, 10, 50, 100\\}.\n",
    "     $$\n",
    "   - Dla każdej wartości `C` oblicz:\n",
    "     - wartość wskaźnika AUC na zbiorze testowym,  \n",
    "     - liczbę niezerowych współczynników modelu.\n",
    "   - Na podstawie wyników wybierz wartość `C`, która stanowi najlepszy kompromis między jakością predykcji a prostotą modelu.\n",
    "\n",
    "\n",
    "   Następnie używając wybranego najlepszego `C`, dopasuj modele regresji logistycznej z regularyzacją Elastic Net, zmieniając parametr  \n",
    "     $$\n",
    "     \\alpha \\in \\{0.0, 0.1, 0.25, 0.5, 0.75, 0.9,  1.0\\}.\n",
    "     $$\n",
    "   - Dla każdej wartości $\\alpha$ oblicz:\n",
    "     - wartość AUC na zbiorze testowym,  \n",
    "     - liczbę niezerowych współczynników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
    "df = credit.frame\n",
    "\n",
    "# Zmienna celu: 1 = good, 0 = bad\n",
    "df['class'] = (df['class'] == 'good').astype(int)\n",
    "\n",
    "# One-hot encoding zmiennych kategorycznych\n",
    "X = pd.get_dummies(df.drop(columns='class'), drop_first=True)\n",
    "y = df['class']\n",
    "\n",
    "# Podział na zbiory treningowy/testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standaryzacja danych\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Optymalizacja parametru C dla regularyzacji L1\n",
    "# -----------------------------\n",
    "C_values = np.logspace(-3, 2, 10)  # od 0.001 do 100\n",
    "results_L1 = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Uwaga\n",
    "\n",
    "Wartość optymalna parametru `C` uzyskana dla regularyzacji **L1** może stanowić **dobry punkt wyjścia** do dalszej optymalizacji w modelu **Elastic Net**.  \n",
    "Jednak ze względu na obecność składnika L2 w funkcji kosztu, **optymalne wartości `C` mogą się różnić** między L1 i Elastic Net.  \n",
    "W praktyce warto:\n",
    "- przeprowadzić osobną optymalizację obu hiperparametrów (`C`, `α`),  \n",
    "- lub rozważyć **otoczenie wartości `C_max`** wyznaczonego dla L1, aby sprawdzić stabilność rozwiązania.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
