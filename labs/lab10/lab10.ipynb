{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wstęp do Uczenia Maszynowego \n",
    "##### Laboratorium 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector, VarianceThreshold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dlaczego chcemy wybierać zmienne:**\n",
    "\n",
    "*Uproszczenie modeli:* Ułatwienie interpretacji dla badaczy i użytkowników.\n",
    "\n",
    "*Krótszy czas trenowania:* Mniejsza ilość danych wejściowych przyspiesza algorytmy.\n",
    "\n",
    "*Lepsza generalizacja:* Zmniejszenie ryzyka przeuczenia (overfitting) poprzez redukcję wariancji.\n",
    "\n",
    "*Unikanie \"przekleństwa wymiarowości\" (Curse of Dimensionality).*\n",
    "\n",
    "*Poprawa dokładności (w wielu przypadkach).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytanie danych\n",
    "X = pd.read_csv(\"X.csv\")\n",
    "y = pd.read_csv(\"y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1012, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Selekcja zmiennych - stałe zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Selekcja zmiennych "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Metoda `SelectFromModel()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html)\n",
    "\n",
    "Wykorzystuje informacje z innego modelu, który posiada metodę ważności zmiennych `feature_importances_` lub współczynniki `coef_`.\n",
    "\n",
    "\n",
    "[Metoda `SequentialFeatureSelector()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html)\n",
    "\n",
    "Metoda dodaje (forward selection) lub usuwa (backward selection) zmienne i tworzy podzbiór w zachłanny sposób. W każdym kroku wybiera najlepszą zmienną, którą dodaje lub usuwa bazując na wartości miary na kroswalidacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "----\n",
    "Wczytaj zbiór danych `X.csv` i `y.csv`, podziel na zbiór treningowy i testowy w stosunku 4:1. \n",
    "\n",
    "a) Przygotuj `pipeline`, który przygotuje dane, uwzględnij w nim odrzucenie zmiennych stałych, dodaj model regresji logistycznej bez regularyzacji.\n",
    "\n",
    "b) Dodaj selekcję zmiennych z wykorzystaniem `SelectFromModel()` w utworzonym `pipeline` w punkcie a). Do funkcji `SelectFromModel()` wykorzystaj model regresji logistycznej a do modelowania wykorzystaj drzewo decyzyjne. Przeprowadź optymalizację hiperparametrów drzewa.\n",
    "\n",
    "c) Przygotuj kolejny `pipeline`, który do wyboru zmiennych zamiast funkcji `SelectFromModel()` wykorzysta funkcję `SequentialFeatureSelector()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analiza Głównych Składowych (PCA)**\n",
    "\n",
    "*Redukcja Wymiarowości:* Umożliwia zmniejszenie liczby cech (zmiennych) w zbiorze danych przy jednoczesnej maksymalizacji zachowania zmienności (informacji) w danych.\n",
    "\n",
    "*Liniowa Transformacja:* Jest to technika liniowa. Tworzy nowe zmienne, które są kombinacjami liniowymi (ważonymi sumami) oryginalnych zmiennych.\n",
    "\n",
    "*Wydobywanie cech (Feature Extraction):* W przeciwieństwie do wyboru cech (Feature Selection), PCA tworzy zupełnie nowe cechy (PC), zamiast po prostu wybierać podzbiór istniejących."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ładowanie zbioru danych\n",
    "wine_data = datasets.load_wine(as_frame=True)\n",
    "df = wine_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2\n",
    "----\n",
    "Wczytaj zbiór danych `pima.csv`.\n",
    "\n",
    "a) Podziel zbiór na treningowy i testowy w proporcji 4:1.\n",
    "\n",
    "b) Na zbiorze treningowym wyznacz komponenty uzyskane metodą PCA. Sporządź wykres, który ukazuje jaki procent wariancji jest wyjaśniany przez kolejne komponenty.\n",
    "\n",
    "c) Dopasuj model regresji logistycznej dla danych treningowych pełnych, dla danych po PCA, dla 5 pierwszych komponentów po PCA, dla 2 pierwszych komponentów po PCA.\n",
    "\n",
    "d) Policz dokładność na zbiorze testowym dla każego modelu z punktu c).\n",
    "\n",
    "e) Przygotuj `pipeline` ze wszystkimi krokami dla modelu regresji logistycznej na danych po PCA i policz dokładność na zbiorze testowym.\n",
    "\n",
    "*Wyniki powinny być takie same jak dla drugiego modelu z punktu c)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytanie danych\n",
    "pima = pd.read_csv(\"pima.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podział na y i X\n",
    "y = pima.Outcome\n",
    "X = pima.drop([\"Outcome\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
