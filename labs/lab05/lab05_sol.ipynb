{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wstęp do Uczenia Maszynowego \n",
    "##### Laboratorium 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 1*\n",
    "------\n",
    "Wczytaj dane `pima.csv`.\n",
    "\n",
    "a) Podziel dane za część treningową i testową (3:2).\n",
    "\n",
    "b) Dopasuj model drzewa do danych treningowych.\n",
    "\n",
    "c) Dopasuj model regresji logistycznej do danych treningowych.\n",
    "\n",
    "d) Podaj miary: czułość, precyzja, AUC dla obu modeli na zbiorze testowym.\n",
    "\n",
    "e) Narysuj krzywą ROC dla obu modeli na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych\n",
    "pima = pd.read_csv(\"../lab02/pima.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział na X i y\n",
    "y = pima.Outcome\n",
    "X = pima.drop(['Outcome'], axis = 1)\n",
    "\n",
    "# Podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "# Model drzewa bez optymalizacji hiperparametrów\n",
    "tree_default = DecisionTreeClassifier()\n",
    "tree_default.fit(X_train, y_train)\n",
    "\n",
    "# Model drzewa z wybranymi hiperparametrami\n",
    "tree = DecisionTreeClassifier(max_depth=7, min_samples_leaf=10)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Model regresji logistycznej\n",
    "glm = LogisticRegression(penalty=None, max_iter = 500)\n",
    "glm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predykcja i wyliczenie metryk\n",
    "y_pred_tree_default = tree_default.predict(X_test)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "y_pred_glm = glm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Model DRZEWA DEFAULT\")\n",
    "print(\"---------------------------\")\n",
    "print(\"precision:\", np.round(precision_score(y_test, y_pred_tree_default), 3))\n",
    "print(\"recall:\", np.round(recall_score(y_test, y_pred_tree_default), 3))\n",
    "print(\"auc:\", )\n",
    "print(\"---------------------------\")\n",
    "\n",
    "print(\"Model DRZEWA\")\n",
    "print(\"---------------------------\")\n",
    "print(\"precision:\", np.round(precision_score(y_test, y_pred_tree), 3))\n",
    "print(\"recall:\", np.round(recall_score(y_test, y_pred_tree), 3))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "print(\"Model REGRESJI LOGISTYCZNEJ\")\n",
    "print(\"---------------------------\")\n",
    "print(\"precision\", np.round(precision_score(y_test, y_pred_glm), 3))\n",
    "print(\"recall:\", np.round(recall_score(y_test, y_pred_glm), 3))\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC i krzywa ROC\n",
    "pred_tree_default = tree_default.predict_proba(X_test)\n",
    "pred_tree = tree.predict_proba(X_test)\n",
    "pred_glm = glm.predict_proba(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_tree_default[:,1])\n",
    "plt.plot(fpr,tpr,label=\"Tree DEFAULT, AUC=\"+str(round(roc_auc_score(y_test, pred_tree_default[:,1]), 4)))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_tree[:,1])\n",
    "plt.plot(fpr,tpr,label=\"Tree, AUC=\"+str(round(roc_auc_score(y_test, pred_tree[:,1]), 4)))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_glm[:,1])\n",
    "plt.plot(fpr,tpr,label=\"LM, AUC=\"+str(round(roc_auc_score(y_test, pred_glm[:,1]), 4)))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 2*\n",
    "------\n",
    "Eksperyment symulacyjny. Wygenerujmy dane w następujący sposób. Niech $n = 200$, $p = 5$. Wektor $\\beta_0 = 1$, $\\beta_1 = [2, 1, 0.5, 0.01, 0]$, $x_i \\sim N_p(0, I)$ dla $i = 1,2, \\dots, n$. $y_i$ pochodzi z rozkładu $Bern(p_i)$, gdzie $p_i=\\frac{exp(\\beta_0 + x_{i\\cdot}\\beta_1)}{1 + exp(\\beta_0 + x_{i\\cdot}\\beta_1)}$.\n",
    "\n",
    "a) Dopasuj model regresji logistycznej. Porównaj prawdziwe wartości wektora $\\beta$ z wyestymowanymi.\n",
    "\n",
    "b) Dopasuj model regresji logistycznej z regularyzacją $L2$ i współczynnikami $C = (10, 5, 2, 1, 0.5, 0.1, 0.01, 0.005)$. jak zmienieją się współczynniki wraz ze wzrostem współczynnika lambda?\n",
    "\n",
    "c) Dopasuj model regresji logistycznej z regularyzacją $L1$ i współczynnikami $C = (10, 5, 2, 1, 0.5, 0.1, 0.01, 0.005)$. jak zmienieją się współczynniki wraz ze wzrostem współczynnika lambda?\n",
    "\n",
    "d) Powtórz eksperyment 500 razy dla modelu logistycznego bez regularyzacji, z regularyzacją $L2$ i parametrem $C=1$ i regularyzacją $L1$ i parametrem $C=1$. Oblicz MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symulacja danych wejściowych\n",
    "n = 200 # liczba obserwacji (wierszy)\n",
    "p = 5 # liczba zmiennych (kolumn)\n",
    "beta_0 = 1 # wyraz wolny\n",
    "beta_1 = np.array([2, 1, 0.5, 0.01, 0]) # współczynniki\n",
    "X = np.random.normal(0, 1, size = (n, p)) # losowanie z rozkładu normalnego wielowymiarowego\n",
    "Xbeta = X@beta_1 + beta_0 \n",
    "probs = np.exp(Xbeta)/(1 + np.exp(Xbeta)) # p_i\n",
    "y = np.random.binomial(1, probs) # wartości y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "# model regresji logistycznej bez regularyzacji\n",
    "lm = LogisticRegression(penalty=None)\n",
    "lm.fit(X, y)\n",
    "print(lm.coef_)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) \n",
    "coefs = []\n",
    "intercepts = []\n",
    "C = np.array([10, 5, 2, 1, 0.5, 0.1, 0.01, 0.005]) # zakres wartości C z polecenia\n",
    "\n",
    "for c in C:\n",
    "    # model regresji logistycznej z karą L2\n",
    "    glm = LogisticRegression(penalty=\"l2\", C = c)\n",
    "    glm.fit(X, y)\n",
    "    coefs.append(glm.coef_[0]) # zapisuję współczynniki\n",
    "    intercepts.append(glm.intercept_[0]) # zapisuję wyraz wolny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykres zależności parametru C (1/lambda) od wartości współczynników\n",
    "plt.plot(1/C, np.array(coefs), label = ['B1', 'B2', 'B3', 'B4', 'B5'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) \n",
    "coefs = []\n",
    "intercepts = []\n",
    "C = np.array([10, 5, 2, 1, 0.5, 0.1, 0.01, 0.005]) # zakres wartości C z polecenia\n",
    "\n",
    "for c in C:\n",
    "    # model regresji logistycznej z karą L1, należy zmieć \"solver\"\n",
    "    glm = LogisticRegression(penalty=\"l1\", C = c, solver = 'liblinear')\n",
    "    glm.fit(X, y)\n",
    "    coefs.append(glm.coef_[0]) # zapisuję współczynniki\n",
    "    intercepts.append(glm.intercept_[0]) # zapisuję wyraz wolny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykres zależności parametru C (1/lambda) od wartości współczynników\n",
    "plt.plot(1/C, np.array(coefs), label = ['B1.1', 'B1.2', 'B1.3', 'B1.4', 'B1.5'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d)\n",
    "k = 500 # liczba eksperymentów \n",
    "n = 200\n",
    "p = 5\n",
    "beta_0 = 1\n",
    "beta_1 = np.array([2, 1, 0.5, 0.01, 0])\n",
    "\n",
    "# miejsce do zapisania wyników\n",
    "MSE = []\n",
    "MSE_l1 = []\n",
    "MSE_l2 = []\n",
    "\n",
    "for i in range(k):\n",
    "    # generowanie danych    \n",
    "    X = np.random.normal(0, 1, size = (n, p))\n",
    "    Xbeta = X@beta_1+beta_0\n",
    "    probs = np.exp(Xbeta)/(1+np.exp(Xbeta)) \n",
    "    y = np.random.binomial(1, probs)\n",
    "    \n",
    "    # model regresji logistycznej bez regularyzacji\n",
    "    lm = LogisticRegression(penalty = None, max_iter = 100)\n",
    "    lm.fit(X,y)\n",
    "\n",
    "    MSE.append(np.sum((lm.coef_ - beta_1)**2 + (lm.intercept_ - beta_0)**2))\n",
    "    \n",
    "    # model regresji logistycznej z karą L1\n",
    "    lm_l1 = LogisticRegression(penalty = 'l1', max_iter = 100, solver = 'liblinear')\n",
    "    lm_l1.fit(X,y)\n",
    "\n",
    "    MSE_l1.append(np.sum((lm_l1.coef_ - beta_1)**2 + (lm_l1.intercept_ - beta_0)**2))\n",
    "\n",
    "    # model regresji logistycznej z karą L2\n",
    "    lm_l2 = LogisticRegression(penalty = 'l2', max_iter = 100)\n",
    "    lm_l2.fit(X,y)\n",
    "    \n",
    "    MSE_l2.append(np.sum((lm_l2.coef_ - beta_1)**2 + (lm_l2.intercept_ - beta_0)**2))\n",
    "\n",
    "print('MSE:', np.round(np.mean(MSE), 5))\n",
    "print('MSE l1:', np.round(np.mean(MSE_l1), 5))\n",
    "print('MSE l2:', np.round(np.mean(MSE_l2), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##### *Zadanie 3*\n",
    "------\n",
    "Wpływ skalowania zmiennych. Dopasuj modele regresji logistycznej\n",
    "1. z regularyzacją L2 dla danych bez skalowania i dla danych ze skalowaniem zmiennych (StandardScaler);\n",
    "2. z regularyzacją L1 dla danych bez skalowania i dla danych ze skalowaniem zmiennych (StandardScaler).\n",
    "\n",
    "Porównaj współczynniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Wczytanie danych\n",
    "credit = fetch_openml(name='credit-g', version=1, as_frame=True)\n",
    "df = credit.frame\n",
    "\n",
    "print(df.shape)\n",
    "# wybranie kilku kolumn\n",
    "sel_cols = ['age', 'existing_credits', 'duration', 'credit_amount', 'savings_status', 'credit_history', 'class']\n",
    "df = df[sel_cols]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodowanie klas\n",
    "df['class'] = (df['class'] == 'good').astype(int)\n",
    "\n",
    "# wybór X i y\n",
    "X = df.drop(columns='class')\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodowanie zmiennych kategorycznych\n",
    "X_dummies = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. z regularyzacją L2 dla danych bez skalowania i dla danych ze skalowaniem zmiennych (StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# podział na próbkę treningową i testową\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_dummies, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# model regresji logistycznej na danych bez skalowanie \n",
    "model_raw = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=5000)\n",
    "model_raw.fit(X_train, y_train)\n",
    "\n",
    "# predykcja\n",
    "y_pred_raw = model_raw.predict(X_test)\n",
    "# auc\n",
    "auc_raw = roc_auc_score(y_test, model_raw.predict_proba(X_test)[:,1])\n",
    "print(\"AUC bez skalowania:\", auc_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nazwy kolumn z wartością współczynników\n",
    "coef_raw = pd.Series(model_raw.coef_[0], index=X.columns)\n",
    "coef_raw.sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# skalowanie zmiennych\n",
    "scaler = StandardScaler()\n",
    "# X_train_s = scaler.fit_transform(X_train)\n",
    "# X_test_s = scaler.transform(X_test)\n",
    "\n",
    "X_s = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X_s, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "model_scaled = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=5000)\n",
    "model_scaled.fit(X_train_s, y_train_s)\n",
    "\n",
    "y_pred_s = model_scaled.predict(X_test_s)\n",
    "auc_scaled = roc_auc_score(y_test_s, model_scaled.predict_proba(X_test_s)[:,1])\n",
    "print(\"AUC po skalowaniu:\", auc_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nazwy kolumn z wartością współczynników\n",
    "coef_scaled = pd.Series(model_scaled.coef_[0], index=X.columns)\n",
    "\n",
    "# porównanie współczynników bez skalowanie i ze skalowaniem\n",
    "comparison = pd.DataFrame({\n",
    "    'coef_raw': coef_raw,\n",
    "    'coef_scaled': coef_scaled\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykres ukazujący różnice w wartościach współczynników dla danych ze skalowaniem i bez\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(np.arange(len(coef_raw)), coef_raw, width=0.4, label='bez skalowania')\n",
    "plt.bar(np.arange(len(coef_scaled))+0.4, coef_scaled, width=0.4, label='po skalowaniu')\n",
    "plt.xlabel(\"Indeks cechy\")\n",
    "plt.ylabel(\"Wartość współczynnika β\")\n",
    "plt.title(\"Wpływ skalowania na współczynniki regresji logistycznej (Credit-G)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. z regularyzacją L1 dla danych bez skalowania i dla danych ze skalowaniem zmiennych (StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model regresji logistycznej na danych bez skalowanie \n",
    "model_l1_raw = LogisticRegression(penalty='l1', solver='saga', C=0.5, max_iter=5000)\n",
    "model_l1_raw.fit(X_train, y_train)\n",
    "coef_l1_raw = pd.Series(model_l1_raw.coef_[0], index=X.columns)\n",
    "print(\"Niezerowe współczynniki (bez skalowania):\", sum(coef_l1_raw != 0)) # liczba niezerowych współczynników\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model regresji logistycznej na danych zez skalowaniem\n",
    "model_l1_scaled = LogisticRegression(penalty='l1', solver='saga', C=0.5, max_iter=5000)\n",
    "model_l1_scaled.fit(X_train_s, y_train_s)\n",
    "coef_l1_scaled = pd.Series(model_l1_scaled.coef_[0], index=X.columns)\n",
    "print(\"Niezerowe współczynniki (po skalowaniu):\", sum(coef_l1_scaled != 0)) # liczba niezerowych współczynników\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porównanie wartości współczynników\n",
    "comparison = pd.DataFrame({\n",
    "    'coef_raw': coef_l1_raw,\n",
    "    'coef_scaled': coef_l1_scaled\n",
    "})\n",
    "comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
